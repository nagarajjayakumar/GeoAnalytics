{"paragraphs":[{"text":"%spark2\n\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.SQLContext\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.{Row, SparkSession}\nimport org.geotools.data.{DataStoreFinder, Query}\nimport org.geotools.factory.CommonFactoryFinder\nimport org.geotools.filter.text.ecql.ECQL\nimport org.locationtech.geomesa.hbase.data.HBaseDataStore\nimport org.locationtech.geomesa.spark.{GeoMesaSpark, GeoMesaSparkKryoRegistrator}\nimport org.opengis.feature.simple.SimpleFeature\n\n\nsc.version\n\nval sparkSession = SparkSession\n      .builder()\n      .appName(\"testSpark\")\n      .config(\"spark.sql.crossJoin.enabled\", \"true\")\n      .config(\"zookeeper.znode.parent\", \"/hbase-unsecure\")\n      .config(\"spark.sql.autoBroadcastJoinThreshold\", 1024*1024*200)\n      .getOrCreate()\n\nval sc = sparkSession.sparkContext\nval sqlContext = new SQLContext(sc)\nsqlContext.udf.register(\"WIDTH_BUCKET_1\" , com.hortonworks.gc.udf.WidthBucket.widthBucket _)   \n\n\n// Site Exposure\nval featureTypeName = \"siteexposure_event\"\n\nval dataFrame = sparkSession.read\n      .format(\"geomesa\")\n      .options(Map(\"bigtable.table.name\" -> \"site_exposure_1M\"))\n      .option(\"geomesa.feature\", featureTypeName)\n      .load()\n     \ndataFrame.createOrReplaceTempView(featureTypeName)\n\n\nval nzgridevent = \"nzgrid_event\"\n\n    val dataFramePolicyExposure = sparkSession.read\n      .format(\"geomesa\")\n      .options(Map(\"bigtable.table.name\" -> \"nzgrid\"))\n      .option(\"geomesa.feature\", nzgridevent)\n      .load()\n\n    dataFramePolicyExposure.createOrReplaceTempView(nzgridevent)\n  \n\n     val sqlQuery2 = \"SELECT count(*)  FROM siteexposure_event as  se, nzgrid_event as nze  where se.nz_grid_id=nze.nz_grid_id and st_intersects(se.geom,  nze.SHAPE ) \"\n    \n   \n val resultDataFrame2 = sparkSession.sql(sqlQuery2)\n    resultDataFrame2.show","user":"admin","dateUpdated":"2017-08-25T16:26:53+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1503406462686_1239971073","id":"20170822-125422_1575242133","dateCreated":"2017-08-22T12:54:22+0000","dateStarted":"2017-08-25T16:26:53+0000","dateFinished":"2017-08-25T16:29:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:207","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.sql.SparkSession\n\nimport org.apache.spark.sql.SQLContext\n\nimport org.apache.hadoop.conf.Configuration\n\nimport org.apache.spark.rdd.RDD\n\nimport org.apache.spark.sql.{Row, SparkSession}\n\nimport org.geotools.data.{DataStoreFinder, Query}\n\nimport org.geotools.factory.CommonFactoryFinder\n\nimport org.geotools.filter.text.ecql.ECQL\n\nimport org.locationtech.geomesa.hbase.data.HBaseDataStore\n\nimport org.locationtech.geomesa.spark.{GeoMesaSpark, GeoMesaSparkKryoRegistrator}\n\nimport org.opengis.feature.simple.SimpleFeature\n\nres68: String = 2.1.1.2.6.1.0-129\n\nsparkSession: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@66c22dce\n\nsc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@6f6700ae\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n\nsqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@6e1c647c\n\nres71: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function4>,LongType,Some(List(DoubleType, DoubleType, DoubleType, LongType)))\n\nfeatureTypeName: String = siteexposure_event\n\ndataFrame: org.apache.spark.sql.DataFrame = [__fid__: string, portfolio_id: bigint ... 107 more fields]\n\nnzgridevent: String = nzgrid_event\n\ndataFramePolicyExposure: org.apache.spark.sql.DataFrame = [__fid__: string, OBJECTID: bigint ... 20 more fields]\n\nsqlQuery2: String = \"SELECT count(*)  FROM siteexposure_event as  se, nzgrid_event as nze  where se.nz_grid_id=nze.nz_grid_id and st_intersects(se.geom,  nze.SHAPE ) \"\n\nresultDataFrame2: org.apache.spark.sql.DataFrame = [count(1): bigint]\n+--------+\n|count(1)|\n+--------+\n| 1974434|\n+--------+\n\n"}]}},{"text":"%spark2\n","user":"admin","dateUpdated":"2017-08-22T12:58:05+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1503406685855_-333946377","id":"20170822-125805_151458274","dateCreated":"2017-08-22T12:58:05+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:208"}],"name":"UseCase_1","id":"2CQZFQS9M","angularObjects":{"2CQ2GZDDE:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CQBK1CKC:shared_process":[],"2CNW8AS1D:shared_process":[],"2CMY8N527:shared_process":[],"2C4U48MY3_spark2:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}