{"paragraphs":[{"text":"%spark2\n\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.SQLContext\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.{Row, SparkSession}\nimport org.geotools.data.{DataStoreFinder, Query}\nimport org.geotools.factory.CommonFactoryFinder\nimport org.geotools.filter.text.ecql.ECQL\nimport org.locationtech.geomesa.hbase.data.HBaseDataStore\nimport org.locationtech.geomesa.spark.{GeoMesaSpark, GeoMesaSparkKryoRegistrator}\nimport org.opengis.feature.simple.SimpleFeature\n\n\nsc.version\n\nval sparkSession = SparkSession\n      .builder()\n      .appName(\"testSpark\")\n      .config(\"spark.sql.crossJoin.enabled\", \"true\")\n      .config(\"zookeeper.znode.parent\", \"/hbase-unsecure\")\n      .config(\"spark.sql.autoBroadcastJoinThreshold\", 1024*1024*200)\n      .getOrCreate()\n\nval sc = sparkSession.sparkContext\nval sqlContext = new SQLContext(sc)\n\nsqlContext.udf.register(\"WIDTH_BUCKET_1\" , com.hortonworks.gc.udf.WidthBucket.widthBucket _)   \n\n\n// Site Exposure\nval featureTypeName = \"siteexposure_event\"\n\nval dataFrame = sparkSession.read\n      .format(\"geomesa\")\n      .options(Map(\"bigtable.table.name\" -> \"site_exposure_1M\"))\n      .option(\"geomesa.feature\", featureTypeName)\n      .load()\n     \ndataFrame.createOrReplaceTempView(featureTypeName)\n\n\nval policyexposureevent = \"policyexposureevent\"\n\n    val dataFramePolicyExposure = sparkSession.read\n      .format(\"geomesa\")\n      .options(Map(\"bigtable.table.name\" -> \"policy_exposure_1M\"))\n      .option(\"geomesa.feature\", policyexposureevent)\n      .load()\n\n    dataFramePolicyExposure.createOrReplaceTempView(policyexposureevent)\n   \n  \n   val portfolioaccountevent = \"portfolioaccountevent\"\n\n    val dataFramePortfolioAccount = sparkSession.read\n      .format(\"geomesa\")\n      .options(Map(\"bigtable.table.name\" -> \"portfolio_account_1M\"))\n      .option(\"geomesa.feature\", portfolioaccountevent)\n      .load()\n\n    dataFramePortfolioAccount.createOrReplaceTempView(portfolioaccountevent)\n    \n\n\n val sqlQuery = \"SELECT MAX((((se.cov1val + se.cov2val) + se.cov3val) + se.cov4val)) AS max_10, se.portfolio_id as portfolio_id, se.site_id as site_id  FROM siteexposure_event se  GROUP BY se.portfolio_id, se.site_id   \"\n  \n   //val sqlQuery = \" select count(*) from sitelossanalyzevent \"\n   \n    val resultDataFrame = sparkSession.sql(sqlQuery)\n    \n    \n    resultDataFrame.createOrReplaceTempView(\"myview\")\n    \n    //val sqlQuery1 = \"SELECT MIN(max_10) AS MIN_VAL, MAX(max_10) AS MAX_VAL, WIDTH_BUCKET_1(max_10, 150.000000, 3990682000.000000, 99) AS BIN, COUNT(1)  AS FREQUENCY FROM myview GROUP BY BIN ORDER BY BIN \"\n    \n    val sqlQuery1 = \"SELECT max_10 , WIDTH_BUCKET_1(max_10, 150.000000, 3990682000.000000, 99) AS BIN, portfolio_id, site_id FROM myview \"\n    \n    val resultDataFrame1 = sparkSession.sql(sqlQuery1)\n    \n    resultDataFrame1.createOrReplaceTempView(\"myview1\")\n    \n     val sqlQuery2 = \"SELECT MIN(max_10) AS MIN_VAL, MAX(max_10) AS MAX_VAL, BIN, COUNT(1)  AS FREQUENCY FROM myview1 where portfolio_id=51326 GROUP BY BIN ORDER BY BIN limit 100 \"\n    \n\n val resultDataFrame2 = sparkSession.sql(sqlQuery2)\n    resultDataFrame2.show\n      ","user":"admin","dateUpdated":"2017-08-21T03:46:53+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.sql.SparkSession\n\nimport org.apache.spark.sql.SQLContext\n\nimport org.apache.hadoop.conf.Configuration\n\nimport org.apache.spark.rdd.RDD\n\nimport org.apache.spark.sql.{Row, SparkSession}\n\nimport org.geotools.data.{DataStoreFinder, Query}\n\nimport org.geotools.factory.CommonFactoryFinder\n\nimport org.geotools.filter.text.ecql.ECQL\n\nimport org.locationtech.geomesa.hbase.data.HBaseDataStore\n\nimport org.locationtech.geomesa.spark.{GeoMesaSpark, GeoMesaSparkKryoRegistrator}\n\nimport org.opengis.feature.simple.SimpleFeature\n\nres113: String = 2.1.1.2.6.1.0-129\n\nsparkSession: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@25a139e5\n\nsc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@2923d241\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n\nsqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@6243ca3f\n\nres117: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function4>,LongType,Some(List(DoubleType, DoubleType, DoubleType, LongType)))\n\nfeatureTypeName: String = siteexposure_event\n\ndataFrame: org.apache.spark.sql.DataFrame = [__fid__: string, portfolio_id: bigint ... 107 more fields]\n\npolicyexposureevent: String = policyexposureevent\n\ndataFramePolicyExposure: org.apache.spark.sql.DataFrame = [__fid__: string, portfolio_id: bigint ... 69 more fields]\n\nportfolioaccountevent: String = portfolioaccountevent\n\ndataFramePortfolioAccount: org.apache.spark.sql.DataFrame = [__fid__: string, portfolio_id: bigint ... 23 more fields]\n\nsqlQuery: String = \"SELECT MAX((((se.cov1val + se.cov2val) + se.cov3val) + se.cov4val)) AS max_10, se.portfolio_id as portfolio_id, se.site_id as site_id  FROM siteexposure_event se  GROUP BY se.portfolio_id, se.site_id   \"\n\nresultDataFrame: org.apache.spark.sql.DataFrame = [max_10: double, portfolio_id: bigint ... 1 more field]\n\nsqlQuery1: String = \"SELECT max_10 , WIDTH_BUCKET_1(max_10, 150.000000, 3990682000.000000, 99) AS BIN, portfolio_id, site_id FROM myview \"\n\nresultDataFrame1: org.apache.spark.sql.DataFrame = [max_10: double, BIN: bigint ... 2 more fields]\n\nsqlQuery2: String = \"SELECT MIN(max_10) AS MIN_VAL, MAX(max_10) AS MAX_VAL, BIN, COUNT(1)  AS FREQUENCY FROM myview1 where portfolio_id=51326 GROUP BY BIN ORDER BY BIN limit 100 \"\n\nresultDataFrame2: org.apache.spark.sql.DataFrame = [MIN_VAL: double, MAX_VAL: double ... 2 more fields]\n+------------+------------+---+---------+\n|     MIN_VAL|     MAX_VAL|BIN|FREQUENCY|\n+------------+------------+---+---------+\n|       150.0|    4.0294E7|  1|   620112|\n| 4.0477274E7|    8.0315E7|  2|     1368|\n| 8.1028143E7|   1.20572E8|  3|      699|\n|   1.21503E8|1.60132029E8|  4|      370|\n|   1.61981E8|   2.01458E8|  5|      270|\n|   2.04374E8|   2.41276E8|  6|      156|\n|2.43565251E8| 2.7809375E8|  7|      112|\n|   2.82918E8|   3.18594E8|  8|       87|\n|3.22845425E8|   3.57457E8|  9|       41|\n|   3.66299E8|3.88874648E8| 10|       51|\n|   4.07056E8|   4.40612E8| 11|       42|\n|   4.74829E8|   4.79562E8| 12|       13|\n|     4.911E8|   5.17497E8| 13|       18|\n| 5.2767403E8|5.55899764E8| 14|       21|\n|   5.77409E8|   6.02138E8| 15|        7|\n|   6.06773E8|6.41028497E8| 16|       23|\n| 6.7600012E8|6.80162653E8| 17|        7|\n|   7.05395E8|   7.05395E8| 18|        2|\n|7.73784458E8|7.73784458E8| 20|        6|\n|   8.27738E8|   8.27738E8| 21|        2|\n+------------+------------+---+---------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1503279269152_-2511643","id":"20170821-013429_2132516045","dateCreated":"2017-08-21T01:34:29+0000","dateStarted":"2017-08-21T03:46:53+0000","dateFinished":"2017-08-21T03:47:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:475"},{"text":"%spark2\n","user":"admin","dateUpdated":"2017-08-21T01:40:50+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1503279650919_877759380","id":"20170821-014050_596302118","dateCreated":"2017-08-21T01:40:50+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:476"}],"name":"Usecase_5","id":"2CQP682VP","angularObjects":{"2CQ2GZDDE:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CQBK1CKC:shared_process":[],"2CNW8AS1D:shared_process":[],"2CMY8N527:shared_process":[],"2C4U48MY3_spark2:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}